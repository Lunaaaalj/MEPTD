---
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE)
setwd("data")

```

Juntando todos los datos de todos los años, se obtiene infofmacion relevante sobre la base de datos

# Estructura:

```{r}


# Install and load required library for combining data frames
if (!require(dplyr, quietly = TRUE)) {
  install.packages("dplyr")
  library(dplyr)
}

if(!require(ggplot2, quietly = TRUE)) {
  install.packages("ggplot2")
  library(ggplot2)
}

# Para las medidas de forma 
if(!require(moments, quietly = TRUE)) {
  install.packages("moments")
  library(moments)
}

# Read CSV files individually first
df_2019 <- read.csv("conjunto_de_datos_molec_2019_02.csv")
df_2020 <- read.csv("conjunto_de_datos_molec_2020_02.csv")
df_2021 <- read.csv("conjunto_de_datos_molec_2021_02.CSV")
df_2022 <- read.csv("conjunto_de_datos_molec_2022_02.CSV")
df_2023 <- read.csv("conjunto_de_datos_molec_2023_02.CSV")
df_2024 <- read.csv("conjunto_de_datos_molec_2024_02.csv")

# Combine data frames properly using rbind() or bind_rows()
df <- bind_rows(df_2019, df_2020, df_2021, df_2022, df_2023, df_2024)

# Display column names using cat() (preferred) or print()

# clean the data frame

df_c = df[,c(4,104,105,107,85,86,87,89,11,17,18,33,34,52,53)]

str(df_c)

# Alternative: just use print() properly
# print(colnames(df))
# Hola, este es mi cambio
# Segundo cambio
```

# Dimensión del data frame

Para encontrar la cantidad de columnas y renglones del data frame se usan las funciones de ncol y nrow

```{r}
ncol(df_c)
nrow(df_c)
```

# Datos faltantes

Variables selectionadas:

```{r}
head(df_c)
```

Analizando el sumario, no se notan discrepancias en los valores

```{r}
summary(df_c)
```

No hay valores vacios

```{r}
colSums(is.na(df_c))
```

Chequeo de rango de los datos cuantitativos

Edad:

```{r}
subset(df_c,edad <0)
subset(df_c,edad>99)
```

Cantidad de libros leidos:

```{r}
subset(df_c,p4<0)
subset(df_c,p4>70)
```

Revistas:

```{r}
subset(df_c,p10<0)
subset(df_c,p10>25)
```

Periodicos:

```{r}
subset(df_c,p16<0)
subset(df_c,p16>60)
```

Conclusion: no hay discrepancias en la base de datos que podrian afectar el analisis

Prepararemos los datos para tener un mejor analisis, esto requiere que se combinen las columnas de la cantidad de libros, revistas y periodicos leidos en una sola columna mas general:

```{r}
df_c$TL=(df_c$p4+df_c$p10+df_c$p16)
head(df_c)
```

# Descripción de variables

Las variables utilizadas se describen a continuación en orden lógico.

Edad: Esta variable indica cuántos años tiene el encuestado, se describe como cuantitativa y es fundamental para nuestro trabajo, ya que la encuesta MOLEC se aplica a partir de una cierta edad. En ella podemos ver que el hábito de lectura varía según la etapa de vida, lo que nos permite distinguir si los estímulos afectan de manera similar a jóvenes o adultos.

Sexo: Este funciona para distinguir a hombres de mujeres. La variable es categórica y es utilizada como factor de control. En las investigaciones se encuentra evidencia de que existen diferencias en los hábitos de lectura. Es importante incluirla para evitar confundir el efecto de la infancia con sesgos de género.

Nivel: Esta variable muestra el nivel educativo alcanzado por las personas. También es categórica, pero indispensable, ya que se suele considerar a la educación como el factor más relevante al momento de analizar los hábitos de lectura. En nuestro proyecto funcionará como variable de control para comprobar si, aunque se tenga educación, los estímulos de la infancia tienen efectos.

Entidad: Este se refiere al estado de residencia de las personas. La consideramos porque la disponibilidad de materiales de lectura varía entre regiones. Al ocupar esta variable, nos permite descartar que las diferencias sean por desigualdades regionales.

P34_1: “Cuando era niño(a), ¿lo llevaban a bibliotecas o librerías?” Esta es una variable categórica que nos enseña la exposición infantil a espacios en los cuales se fomentaba la lectura. Es funcional para indicar si la familia promovía la lectura fuera de la escuela como parte de su cultura.

P34_2: “Cuando era niño(a), ¿veía a sus padres o tutores leer?” Variable categórica que mide el nivel de lectura en el hogar, ya que ver a los padres leer es un gran ejemplo que influye en la formación del hábito de la lectura de las personas.

P34_3: “Cuando era niño(a), ¿sus padres o tutores le leían en voz alta?” Otra variable categórica en la cual se tiene una exposición directa con la lectura durante la infancia. Esta práctica es conocida por su impacto en el desarrollo cognitivo y se puede considerar un estímulo clave en la lectura.

P34_4: “En su casa, ¿había libros distintos a los de texto escolar?” Variable categórica que nos indica la cantidad de libros que hay en cada hogar, ya que esto representa un recurso material que puede influir en el interés por leer a edad temprana.

P2: “¿Usted acostumbra leer?” Una variable categórica que funciona como un filtro principal para conocer el hábito lector de las personas. Con esto podemos identificar a quienes practican la lectura y a quienes no.

P4: “¿Cuántos libros leyó en los últimos doce meses?” Esta es una variable cuantitativa que nos indica la intensidad del hábito lector. Además de mostrar si las personas leen, también nos dice la cantidad de libros que consumen al año.

P5: “¿Cuál fue el principal motivo por el que leyó libros?” Variable categórica importante, ya que es un gran indicador dentro del análisis. Con esto podemos identificar a las personas que leen por placer o a quienes lo hacen por trabajo.

P10 y P11: “¿Cuántas revistas leyó en los últimos tres meses?” y “¿Cuál fue el motivo principal por el que leyó estas revistas?” Estas variables pueden funcionar como complementarias y permiten observar la lectura de revistas como parte del hábito lector. Es importante porque muchas personas tienen interés en leer materiales impresos o de tendencia.

P16 y P17: “¿Cuántos periódicos leyó la semana pasada?” y “¿Cuál fue el motivo principal por el que leyó el (los) periódico(s)?” Esta variable es complementaria, ya que nos permite analizar la lectura de prensa, lo que enriquece la visión de los hábitos de lectura. Con esto observamos que existe una gran diversidad de medios en los cuales se manifiesta la práctica lectora.

# A. Exploracion de datos

## 1. Calculo de medias estadisticas

### Variables cuantitativas

```{r}
# ----MEDIDAS DE TENDENCIA CENTRAL----

# Media
media_edad = mean(df_c$edad)
media_p4 = mean(df_c$p4)
media_p10 = mean(df_c$p10)
media_p16 = mean(df_c$p16)
media_TL = mean(df_c$TL)
# Mediana
mediana_edad = median(df_c$edad)
mediana_p4 = median(df_c$p4)
mediana_p10 = median(df_c$p10)
mediana_p16 = median(df_c$p16)
mediana_TL = median(df_c$TL)
# Rango medio
rm_edad = (min(df_c$edad)+max(df_c$edad))/2
rm_p4 = (min(df_c$p4)+max(df_c$p4))/2
rm_p10 = (min(df_c$p10)+max(df_c$p10))/2
rm_p16 = (min(df_c$p16)+max(df_c$p16))/2
rm_TL = (min(df_c$TL)+max(df_c$TL))/2

# Generamos una tabla que nos da el resumen final de las medidas de tendencia central
resumen_tendencia_central = data.frame(
  nombreVariable = c("Edad", "Libros(p4)", "Revistas(p10)", "Periódicos(p16)", "Total leído(TL)"),
  media = c(media_edad, media_p4, media_p10, media_p16, media_TL),
  mediana = c(mediana_edad, mediana_p4, mediana_p10, mediana_p16, mediana_TL),
  rangoMedio = c(rm_edad, rm_p4, rm_p10, rm_p16, rm_TL)
)

# ----MEDIDAS DE DISPERSIÓN----

# Desviación estándar
sd_edad = sd(df_c$edad)
sd_p4 = sd(df_c$p4)
sd_p10 = sd(df_c$p10)
sd_p16 = sd(df_c$p16)
sd_TL = sd(df_c$TL)
# Varianza
var_edad = var(df_c$edad)
var_p4 = var(df_c$p4)
var_p10 = var(df_c$p10)
var_p16 = var(df_c$p16)
var_TL = var(df_c$TL)
# Coeficiente de variación
coefvar_edad = (sd(df_c$edad)/mean(df_c$edad))*100
coefvar_p4 = (sd(df_c$p4)/mean(df_c$p4))*100
coefvar_p10 = (sd(df_c$p10)/mean(df_c$p10))*100
coefvar_p16 = (sd(df_c$p16)/mean(df_c$p16))*100
coefvar_TL = (sd(df_c$TL)/mean(df_c$TL))*100

# Generamos una tabla que nos da el resumen final de las medidas de dispersión
resumen_dispersion = data.frame(
  nombreVariable = c("Edad", "Libros(p4)", "Revistas(p10)", "Periódicos(p16)", "Total leído(TL)"),
  desviacionEstandar = c(sd_edad, sd_p4, sd_p10, sd_p16, sd_TL),
  varianza = c(var_edad, var_p4, var_p10, var_p16, var_TL),
  coefVariacion = c(coefvar_edad, coefvar_p4, coefvar_p10, coefvar_p16, coefvar_TL)
)

# ----MEDIDAS DE POSICIÓN----

# Cuartil 1
Q1_edad = quantile(df_c$edad, probs = 0.25)
Q1_p4 = quantile(df_c$p4, probs = 0.25)
Q1_p10 = quantile(df_c$p10, probs = 0.25)
Q1_p16 = quantile(df_c$p16, probs = 0.25)
Q1_TL = quantile(df_c$TL, probs = 0.25)

# Cuartil 2
Q2_edad = quantile(df_c$edad, probs = 0.5)
Q2_p4 = quantile(df_c$p4, probs = 0.5)
Q2_p10 = quantile(df_c$p10, probs = 0.5)
Q2_p16 = quantile(df_c$p16, probs = 0.5)
Q2_TL = quantile(df_c$TL, probs = 0.5)

# Cuartil 1
Q3_edad = quantile(df_c$edad, probs = 0.75)
Q3_p4 = quantile(df_c$p4, probs = 0.75)
Q3_p10 = quantile(df_c$p10, probs = 0.75)
Q3_p16 = quantile(df_c$p16, probs = 0.75)
Q3_TL = quantile(df_c$TL, probs = 0.75)

# Generamos una tabla que nos da el resumen final de las medidas de posición
resumen_posicion = data.frame(
  nombreVariable = c("Edad", "Libros(p4)", "Revistas(p10)", "Periódicos(p16)", "Total leído(TL)"),
  Q1_0.25 = c(Q1_edad, Q1_p4, Q1_p10, Q1_p16, Q1_TL),
  Q2_0.5 = c(Q2_edad, Q2_p4, Q2_p10, Q2_p16, Q2_TL),
  Q3_0.75 = c(Q3_edad, Q3_p4, Q3_p10, Q3_p16, Q3_TL)
)

# ----MEDIDAS DE FORMA----

# Sesgo
sesgo_edad = skewness(df_c$edad)
sesgo_p4 = skewness(df_c$p4)
sesgo_p10 = skewness(df_c$p10)
sesgo_p16 = skewness(df_c$p16)
sesgo_TL = skewness(df_c$TL)

#Curtosis
curtosis_edad = kurtosis(df_c$edad)
curtosis_p4 = kurtosis(df_c$p4)
curtosis_p10 = kurtosis(df_c$p10)
curtosis_p16 = kurtosis(df_c$p16)
curtosis_TL = kurtosis(df_c$TL)

# Generamos una tabla que nos da el resumen final de las medidas de forma
resumen_medidas_forma = data.frame(
  nombreVariable = c("Edad", "Libros(p4)", "Revistas(p10)", "Periódicos(p16)", "Total leído(TL)"),
  Sesgo = c(sesgo_edad, sesgo_p4, sesgo_p10, sesgo_p16, sesgo_TL),
  Curtosis = c(curtosis_edad, curtosis_p4, curtosis_p10, curtosis_p16, curtosis_TL)
)

# ----IMPRIMIR RESULTADOS----

# Imprimimos el resumen de las medidas de tendencia central
print(resumen_tendencia_central)
# Imprimimos el resumen de las medidas de dispersión
print(resumen_dispersion)
# Imprimimos el resumen de las medidas de posición
print(resumen_posicion)
# Imprimimos el resumen de las medidas de forma
print(resumen_medidas_forma)

```

### Variables cualitativas

```{r}
# ---- PREPARACIÓN DE VARIABLES CUALITATIVAS ----

# Convertimos las variables a "factor" para que R las entienda como categorías
df_c$sexo = as.factor(df_c$sexo)
df_c$entidad = as.factor(df_c$entidad)
df_c$p34_1 = as.factor(df_c$p34_1)
df_c$p34_2 = as.factor(df_c$p34_2)
df_c$p34_3 = as.factor(df_c$p34_3)
df_c$p34_4 = as.factor(df_c$p34_4)
df_c$p2 = as.factor(df_c$p2)
df_c$p5 = as.factor(df_c$p5)
df_c$p11 = as.factor(df_c$p11)
df_c$p17 = as.factor(df_c$p17)

```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: SEXO ----

# Recodificamos la variable con etiquetas claras
sexo_factor = factor(df_c$sexo, levels = c(1, 2), labels = c("Hombre", "Mujer"))

# Calculamos la tabla de frecuencia absoluta (conteo)
frecuencias_sexo = table(sexo_factor)

# Generamos la tabla de resumen completa
resumen_sexo = data.frame(
  Categoria = names(frecuencias_sexo),
  Frecuencia = as.vector(frecuencias_sexo),
  Porcentaje = round(prop.table(frecuencias_sexo) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: SEXO")
print(resumen_sexo)

```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: ENTIDAD ----

# Calculamos la tabla de frecuencia absoluta
frecuencias_entidad = table(df_c$entidad)

# Generamos la tabla de resumen completa
resumen_entidad = data.frame(
  Codigo_Entidad = names(frecuencias_entidad),
  Frecuencia = as.vector(frecuencias_entidad),
  Porcentaje = round(prop.table(frecuencias_entidad) * 100, 2)
)

# Mostramos los primeros 10 resultados de la tabla
print("Tabla de Frecuencias: ENTIDAD (primeros 10 de 32)")
print(resumen_entidad)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P34_1 (Llevaban a bibliotecas) ----

# Recodificamos la variable con etiquetas claras
p34_1_factor = factor(df_c$p34_1, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_1 = table(p34_1_factor)

# Generamos la tabla de resumen completa
resumen_p34_1 = data.frame(
  Categoria = names(frecuencias_p34_1),
  Frecuencia = as.vector(frecuencias_p34_1),
  Porcentaje = round(prop.table(frecuencias_p34_1) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P34_1 (Llevaban a bibliotecas)")
print(resumen_p34_1)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P34_2 (veía a sus padres o tutores leer) ----

# Recodificamos la variable con etiquetas claras
p34_2_factor = factor(df_c$p34_2, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_2 = table(p34_2_factor)

# Generamos la tabla de resumen completa
resumen_p34_2 = data.frame(
  Categoria = names(frecuencias_p34_2),
  Frecuencia = as.vector(frecuencias_p34_2),
  Porcentaje = round(prop.table(frecuencias_p34_2) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P34_2 (veía a sus padres o tutores leer)")
print(resumen_p34_2)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P34_3 (Sus padres o tutores le leían en voz alta) ----

# Recodificamos la variable con etiquetas claras
p34_3_factor = factor(df_c$p34_3, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_3 = table(p34_3_factor)

# Generamos la tabla de resumen completa
resumen_p34_3 = data.frame(
  Categoria = names(frecuencias_p34_3),
  Frecuencia = as.vector(frecuencias_p34_3),
  Porcentaje = round(prop.table(frecuencias_p34_3) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P34_3 (sus padres o tutores le leían en voz alta)")
print(resumen_p34_2)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P34_4 (en su casa había libros distintos a los de texto escolar) ----

# Recodificamos la variable con etiquetas claras
p34_4_factor = factor(df_c$p34_4, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_4 = table(p34_4_factor)

# Generamos la tabla de resumen completa
resumen_p34_4 = data.frame(
  Categoria = names(frecuencias_p34_4),
  Frecuencia = as.vector(frecuencias_p34_4),
  Porcentaje = round(prop.table(frecuencias_p34_4) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P34_3 (en su casa había libros distintos a los de texto escolar)")
print(resumen_p34_4)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P2 (Acostumbra leer) ----

# Recodificamos la variable con etiquetas claras
p2_factor = factor(df_c$p2, levels = c(1, 2), labels = c("Sí", "No"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p2 = table(p2_factor)

# Generamos la tabla de resumen completa
resumen_p2 = data.frame(
  Categoria = names(frecuencias_p2),
  Frecuencia = as.vector(frecuencias_p2),
  Porcentaje = round(prop.table(frecuencias_p2) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P2 (Acostumbra leer)")
print(resumen_p2)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P5 (Motivo de lectura de libros) ----

# Recodificamos la variable con etiquetas claras
p5_factor = factor(df_c$p5, levels = c(1, 2, 3, 4, 5, 6), labels = c("Trabajo", "Estudio", "Cultura General", "Gusto/Entretenimiento", "Religión", "Otro"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p5 = table(p5_factor)

# Generamos la tabla de resumen completa
resumen_p5 = data.frame(
  Categoria = names(frecuencias_p5),
  Frecuencia = as.vector(frecuencias_p5),
  Porcentaje = round(prop.table(frecuencias_p5) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P5 (Motivo lectura libros)")
print(resumen_p5)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P11 (Motivo de lectura de revistas) ----

# Recodificamos la variable con etiquetas claras
p11_factor = factor(df_c$p11, levels = c(1, 2, 3, 4, 5, 6), labels = c("Trabajo", "Estudio", "Cultura General", "Gusto/Entretenimiento", "Religión", "Otro"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p11 = table(p11_factor)

# Generamos la tabla de resumen completa
resumen_p11 = data.frame(
  Categoria = names(frecuencias_p11),
  Frecuencia = as.vector(frecuencias_p11),
  Porcentaje = round(prop.table(frecuencias_p11) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P11 (Motivo lectura de revistas)")
print(resumen_p11)
```

```{r}
# ---- ANÁLISIS DE FRECUENCIA: P17 (Motivo de lectura de periódicos) ----

# Recodificamos la variable con etiquetas claras
p17_factor = factor(df_c$p17, levels = c(1, 2, 3, 4, 5, 6), labels = c("Trabajo", "Estudio", "Cultura General", "Gusto/Entretenimiento", "Religión", "Otro"))

# Calculamos la tabla de frecuencia absoluta
frecuencias_p17 = table(p17_factor)

# Generamos la tabla de resumen completa
resumen_p17 = data.frame(
  Categoria = names(frecuencias_p17),
  Frecuencia = as.vector(frecuencias_p17),
  Porcentaje = round(prop.table(frecuencias_p17) * 100, 2)
)

# Mostramos la tabla
print("Tabla de Frecuencias: P17 (Motivo lectura de periódicos)")
print(resumen_p17)
```

## Herramientas de visualizacion

### Variables cuantitativas

Grafica de dispersion: Textos leidos vs edad

```{r}
ggplot(data = df_c[,c("edad","TL")], aes(x=edad,y=TL)) +
        geom_jitter(size = 0.7)
```

Gran cantidad de valores atipicos, mayor densidad cerca del 0, se nota una baja o nula coorrelacion debido a que es constante cerca del cero

Grafica de barras: Textos leidos vs cantidad de gente

```{r}
ggplot(data = df_c[,c("edad","TL")], aes(x=TL)) +
        geom_bar() +
        stat_function(fun = dnorm,args = list(mean = mean(df_c$TL), sd = sd(df_c$TL)), linewidth = 1) +
        xlim(0,30) +
        ylim(0,1500) +
        geom_vline(xintercept =mean(df_c$TL), aes(x = TL),color = "red",linewidth=1.3)
```

Densidad de cantidad de libros leidos

```{r}
ggplot(data = df_c, aes(x = TL)) +
        geom_density(alpha= 1) +
        xlim(0,50)
```

Distribucion asimetrica con sesgo a la izquierda

Boxplot:

```{r}
ggplot(data = df_c, aes(x = TL, y = edad)) +
        geom_boxplot(fill = "red")
```

### Análisis de correlacion

Como ya se vio en las graficas anteriores, la probabilidad que haya una correlacion entre la edad y la cantidad de textos leidos de una persona es muy baja. Tambien se puede calcular con la funcion cor(), con esta se observa que la correlacion es virtualmente nula.

```{r}
cor(df_c$TL,df_c$edad)
```

### Variables categoricas

Cantidad de personas que fueron a una libreria en su infancia

```{r}
yes_people=nrow(subset(df_c,p34_1==1))
no_people=nrow(subset(df_c,p34_1==2))
other = nrow(df_c)-yes_people-no_people
vec=c(yes_people,no_people,other)
labels=c("Yes","No","Other")
pie(vec,labels)
```

Nuestro objetivo es analizar como se relacionan las tendencias de lectura con variables categoricas como la manera en la que desarrollaron su infancia y educacion.

A continuacion se realizan graficos de dispersion relacionando las variables categoricas con la cantidad de textos leidos

```{r}
ggplot(df_c, aes(x = p34_1, y = TL)) +
        geom_point(position = position_jitter(width = 0.1), alpha = 0.5) +
        labs(title = "lo llevaban a bibliotecas o librerias?",
              x = "1: si, 2: no, otros: nulos", y =  "Cantidad de textos leidos")
```

Porcentaje de personas que acostumbran leer

```{r}
ggplot(df_c, aes(x = p2)) +
        geom_bar() +
        labs(title = "Acostumbra leer?", y = "cantidad de personas", xv="1: si, 2: no, 0: nulo")
```

# Vinculacion de datos categoricos

## Medidas de variables cuantitativas

## Graficos cuantitativos

## Graficos comparativos

## Intervalos de confianza
```{r}
# ---- INTERVALOS DE CONFIANZA (α = 0.04 → 96%) ----

# Ponemos el nivel de significancia y calculamos el z crítico
nivel_significancia = 0.04
confianza = 1 - nivel_significancia
z_critico = qnorm(1 - nivel_significancia/2)

# ---- 1) Proporción que lee por gusto (P5) ----
# Checamos cuántos respondieron P5 y cuántos leen por gusto
n_p5 = sum(!is.na(p5_factor))
k_p5_gusto = sum(p5_factor == "Gusto/Entretenimiento", na.rm = TRUE)
prop_p5_gusto = k_p5_gusto / n_p5

# Sacamos el error estándar y el intervalo al 96%
se_prop_p5 = sqrt(prop_p5_gusto * (1 - prop_p5_gusto) / n_p5)
ic_prop_p5_inf = prop_p5_gusto - z_critico * se_prop_p5
ic_prop_p5_sup = prop_p5_gusto + z_critico * se_prop_p5

cat("1) Proporción P5 = 'Gusto/Entretenimiento'\n")
cat("n =", n_p5, "k =", k_p5_gusto, "\n")
cat("p̂ =", round(prop_p5_gusto,4),
    "IC 96% = [", round(ic_prop_p5_inf,4), ",", round(ic_prop_p5_sup,4), "]\n\n")

# ---- 2) Diferencia de proporciones (Libros en casa Sí vs No) ----
# Separamos los que tienen libros en casa (Sí/No)
n_libro_si = sum(!is.na(p5_factor) & p34_4_factor == "Sí")
n_libro_no = sum(!is.na(p5_factor) & p34_4_factor == "No")

# Contamos cuántos leen por gusto en cada grupo
k_libro_si = sum(p5_factor == "Gusto/Entretenimiento" & p34_4_factor == "Sí", na.rm = TRUE)
k_libro_no = sum(p5_factor == "Gusto/Entretenimiento" & p34_4_factor == "No", na.rm = TRUE)

# Sacamos proporciones en cada grupo
p_si = ifelse(n_libro_si > 0, k_libro_si / n_libro_si, NA)
p_no = ifelse(n_libro_no > 0, k_libro_no / n_libro_no, NA)

# Calculamos la diferencia y su error estándar
diff_prop = p_si - p_no
se_diff_prop = sqrt((p_si*(1-p_si)/n_libro_si) + (p_no*(1-p_no)/n_libro_no))

# Armamos el intervalo al 96%
ic_diff_inf = diff_prop - z_critico * se_diff_prop
ic_diff_sup = diff_prop + z_critico * se_diff_prop

cat("2) Diferencia de proporciones (Libros en casa: Sí vs No)\n")
cat("n(Sí) =", n_libro_si, "k(Sí) =", k_libro_si, " p1 =", round(p_si,4), "\n")
cat("n(No) =", n_libro_no, "k(No) =", k_libro_no, " p2 =", round(p_no,4), "\n")
cat("p1 - p2 =", round(diff_prop,4),
    "IC 96% = [", round(ic_diff_inf,4), ",", round(ic_diff_sup,4), "]\n\n")

# ---- 3) Media del total leído (TL) ----
# Limpiamos los NA y sacamos media, desviación y error estándar
tl = df_c$TL
tl = tl[!is.na(tl)]
n_tl = length(tl)
media_tl = mean(tl)
sd_tl = sd(tl)
se_media_tl = sd_tl / sqrt(n_tl)

# Sacamos el t crítico y el intervalo al 96%
t_critico = qt(1 - nivel_significancia/2, df = n_tl - 1)
ic_media_tl_inf = media_tl - t_critico * se_media_tl
ic_media_tl_sup = media_tl + t_critico * se_media_tl

cat("3) Media TL (total leído)\n")
cat("n =", n_tl, "media =", round(media_tl,4), "sd =", round(sd_tl,4), "\n")
cat("IC 96% (t) = [", round(ic_media_tl_inf,4), ",", round(ic_media_tl_sup,4), "]\n\n")

# ---- 4) Varianza del número de libros leídos (p4) ----
# Quitamos NA y sacamos varianza muestral
p4 = df_c$p4
p4 = p4[!is.na(p4)]
n_p4 = length(p4)
s2_p4 = var(p4)

# Calculamos los valores críticos chi-cuadrado y armamos el IC
chi_inf = qchisq(1 - nivel_significancia/2, df = n_p4 - 1)
chi_sup = qchisq(nivel_significancia/2, df = n_p4 - 1)
ic_var_inf = ((n_p4 - 1) * s2_p4) / chi_inf
ic_var_sup = ((n_p4 - 1) * s2_p4) / chi_sup

cat("4) Varianza p4 (número de libros leídos)\n")
cat("n =", n_p4, "s^2 =", round(s2_p4,4), "\n")
cat("IC 96% para σ^2 = [", round(ic_var_inf,4), ",", round(ic_var_sup,4), "]\n\n")

# ---- Resumen de los intervalos ----
resumen_ICs = data.frame(
  Indicador = c(
    "Proporción que lee por gusto (P5)",
    "Diferencia proporciones (Libros en casa Sí - No)",
    "Media del total leído (TL)",
    "Varianza del número de libros leídos (P4)"
  ),
  Estimador = round(c(prop_p5_gusto, diff_prop, media_tl, s2_p4), 4),
  IC_Inferior = round(c(ic_prop_p5_inf, ic_diff_inf, ic_media_tl_inf, ic_var_inf), 4),
  IC_Superior = round(c(ic_prop_p5_sup, ic_diff_sup, ic_media_tl_sup, ic_var_sup), 4)
)

print("Resumen de intervalos de confianza (IC 96%)")
print(resumen_ICs)

# ---- Conclusión ----

# En general, calculamos los intervalos de confianza con los métodos clásicos: proporciones con z, medias con t y varianzas con chi-cuadrado. Escogimos un nivel de significancia de 0.04 (IC del 96%) para tener un poco más de confianza. Con estos resultados, vemos en qué rango probable se encuentran las proporciones, medias y varianzas reales de la población. Así, podemos interpretar qué tan precisas son las estimaciones a partir de los datos de la muestra.

```

