# Set working directory to the correct folder (Datos, not data)
#setwd("/Users/angelluna/Documents/STEM_PROJECTS/R_Projects_2/MEPTD/data")
# Set working directory (Rafael)
setwd("/Users/hisen/OneDrive/Documentos/ProyectosR_Estadistica3ro/MEPTD/Data")
yes_people=nrow(subset(df_c,p34_1==1))
no_people=nrow(subset(df_c,p34_1==2))
other = nrow(df_c)-yes_people-no_people
vec=c(yes_people,no_people,other)
labels=c("Yes","No","Other")
pie(vec,labels)
cor(df_c$TL,df_c$edad)
ggplot(data = df_c, aes(x = TL, y = edad)) +
geom_boxplot(fill = "red")
# Set working directory to the correct folder (Datos, not data)
#setwd("/Users/angelluna/Documents/STEM_PROJECTS/R_Projects_2/MEPTD/data")
# Set working directory (Rafael)
setwd("/Users/hisen/OneDrive/Documentos/ProyectosR_Estadistica3ro/MEPTD/Data")
ncol(df_c)
nrow(df_c)
head(df_c)
summary(df_c)
colSums(is.na(df_c))
subset(df_c,edad <0)
subset(df_c,edad>99)
subset(df_c,p4<0)
subset(df_c,p4>70)
subset(df_c,p10<0)
subset(df_c,p10>25)
subset(df_c,p16<0)
subset(df_c,p16>60)
df_c$TL=(df_c$p4+df_c$p10+df_c$p16)
head(df_c)
# ----MEDIDAS DE TENDENCIA CENTRAL----
# Media
media_edad = mean(df_c$edad)
media_p4 = mean(df_c$p4)
media_p10 = mean(df_c$p10)
media_p16 = mean(df_c$p16)
media_TL = mean(df_c$TL)
# Mediana
mediana_edad = median(df_c$edad)
mediana_p4 = median(df_c$p4)
mediana_p10 = median(df_c$p10)
mediana_p16 = median(df_c$p16)
mediana_TL = median(df_c$TL)
# Rango medio
rm_edad = (min(df_c$edad)+max(df_c$edad))/2
rm_p4 = (min(df_c$p4)+max(df_c$p4))/2
rm_p10 = (min(df_c$p10)+max(df_c$p10))/2
rm_p16 = (min(df_c$p16)+max(df_c$p16))/2
rm_TL = (min(df_c$TL)+max(df_c$TL))/2
# Generamos una tabla que nos da el resumen final de las medidas de tendencia central
resumen_tendencia_central = data.frame(
nombreVariable = c("Edad", "Libros(p4)", "Revistas(p10)", "Periódicos(p16)", "Total leído(TL)"),
media = c(media_edad, media_p4, media_p10, media_p16, media_TL),
mediana = c(mediana_edad, mediana_p4, mediana_p10, mediana_p16, mediana_TL),
rangoMedio = c(rm_edad, rm_p4, rm_p10, rm_p16, rm_TL)
)
# ----MEDIDAS DE DISPERSIÓN----
# Desviación estándar
sd_edad = sd(df_c$edad)
sd_p4 = sd(df_c$p4)
sd_p10 = sd(df_c$p10)
sd_p16 = sd(df_c$p16)
sd_TL = sd(df_c$TL)
# Varianza
var_edad = var(df_c$edad)
var_p4 = var(df_c$p4)
var_p10 = var(df_c$p10)
var_p16 = var(df_c$p16)
var_TL = var(df_c$TL)
# Coeficiente de variación
coefvar_edad = (sd(df_c$edad)/mean(df_c$edad))*100
coefvar_p4 = (sd(df_c$p4)/mean(df_c$p4))*100
coefvar_p10 = (sd(df_c$p10)/mean(df_c$p10))*100
coefvar_p16 = (sd(df_c$p16)/mean(df_c$p16))*100
coefvar_TL = (sd(df_c$TL)/mean(df_c$TL))*100
# Generamos una tabla que nos da el resumen final de las medidas de dispersión
resumen_dispersion = data.frame(
nombreVariable = c("Edad", "Libros(p4)", "Revistas(p10)", "Periódicos(p16)", "Total leído(TL)"),
desviacionEstandar = c(sd_edad, sd_p4, sd_p10, sd_p16, sd_TL),
varianza = c(var_edad, var_p4, var_p10, var_p16, var_TL),
coefVariacion = c(coefvar_edad, coefvar_p4, coefvar_p10, coefvar_p16, coefvar_TL)
)
# ----MEDIDAS DE POSICIÓN----
# Cuartil 1
Q1_edad = quantile(df_c$edad, probs = 0.25)
Q1_p4 = quantile(df_c$p4, probs = 0.25)
Q1_p10 = quantile(df_c$p10, probs = 0.25)
Q1_p16 = quantile(df_c$p16, probs = 0.25)
Q1_TL = quantile(df_c$TL, probs = 0.25)
# Cuartil 2
Q2_edad = quantile(df_c$edad, probs = 0.5)
Q2_p4 = quantile(df_c$p4, probs = 0.5)
Q2_p10 = quantile(df_c$p10, probs = 0.5)
Q2_p16 = quantile(df_c$p16, probs = 0.5)
Q2_TL = quantile(df_c$TL, probs = 0.5)
# Cuartil 1
Q3_edad = quantile(df_c$edad, probs = 0.75)
Q3_p4 = quantile(df_c$p4, probs = 0.75)
Q3_p10 = quantile(df_c$p10, probs = 0.75)
Q3_p16 = quantile(df_c$p16, probs = 0.75)
Q3_TL = quantile(df_c$TL, probs = 0.75)
# Generamos una tabla que nos da el resumen final de las medidas de posición
resumen_posicion = data.frame(
nombreVariable = c("Edad", "Libros(p4)", "Revistas(p10)", "Periódicos(p16)", "Total leído(TL)"),
Q1_0.25 = c(Q1_edad, Q1_p4, Q1_p10, Q1_p16, Q1_TL),
Q2_0.5 = c(Q2_edad, Q2_p4, Q2_p10, Q2_p16, Q2_TL),
Q3_0.75 = c(Q3_edad, Q3_p4, Q3_p10, Q3_p16, Q3_TL)
)
# ----MEDIDAS DE FORMA----
# Sesgo
sesgo_edad = skewness(df_c$edad)
# ---- PREPARACIÓN DE VARIABLES CUALITATIVAS ----
# Convertimos las variables a "factor" para que R las entienda como categorías
df_c$sexo = as.factor(df_c$sexo)
df_c$entidad = as.factor(df_c$entidad)
df_c$p34_1 = as.factor(df_c$p34_1)
df_c$p34_2 = as.factor(df_c$p34_2)
df_c$p34_3 = as.factor(df_c$p34_3)
df_c$p34_4 = as.factor(df_c$p34_4)
df_c$p2 = as.factor(df_c$p2)
df_c$p5 = as.factor(df_c$p5)
df_c$p11 = as.factor(df_c$p11)
df_c$p17 = as.factor(df_c$p17)
# ---- ANÁLISIS DE FRECUENCIA: SEXO ----
# Recodificamos la variable con etiquetas claras
sexo_factor = factor(df_c$sexo, levels = c(1, 2), labels = c("Hombre", "Mujer"))
# Calculamos la tabla de frecuencia absoluta (conteo)
frecuencias_sexo = table(sexo_factor)
# Generamos la tabla de resumen completa
resumen_sexo = data.frame(
Categoria = names(frecuencias_sexo),
Frecuencia = as.vector(frecuencias_sexo),
Porcentaje = round(prop.table(frecuencias_sexo) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: SEXO")
print(resumen_sexo)
# ---- ANÁLISIS DE FRECUENCIA: ENTIDAD ----
# Calculamos la tabla de frecuencia absoluta
frecuencias_entidad = table(df_c$entidad)
# Generamos la tabla de resumen completa
resumen_entidad = data.frame(
Codigo_Entidad = names(frecuencias_entidad),
Frecuencia = as.vector(frecuencias_entidad),
Porcentaje = round(prop.table(frecuencias_entidad) * 100, 2)
)
# Mostramos los primeros 10 resultados de la tabla
print("Tabla de Frecuencias: ENTIDAD (primeros 10 de 32)")
print(resumen_entidad)
# ---- ANÁLISIS DE FRECUENCIA: P34_1 (Llevaban a bibliotecas) ----
# Recodificamos la variable con etiquetas claras
p34_1_factor = factor(df_c$p34_1, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_1 = table(p34_1_factor)
# Generamos la tabla de resumen completa
resumen_p34_1 = data.frame(
Categoria = names(frecuencias_p34_1),
Frecuencia = as.vector(frecuencias_p34_1),
Porcentaje = round(prop.table(frecuencias_p34_1) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P34_1 (Llevaban a bibliotecas)")
print(resumen_p34_1)
# ---- ANÁLISIS DE FRECUENCIA: P34_2 (veía a sus padres o tutores leer) ----
# Recodificamos la variable con etiquetas claras
p34_2_factor = factor(df_c$p34_2, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_2 = table(p34_2_factor)
# Generamos la tabla de resumen completa
resumen_p34_2 = data.frame(
Categoria = names(frecuencias_p34_2),
Frecuencia = as.vector(frecuencias_p34_2),
Porcentaje = round(prop.table(frecuencias_p34_2) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P34_2 (veía a sus padres o tutores leer)")
print(resumen_p34_2)
# ---- ANÁLISIS DE FRECUENCIA: P34_3 (Sus padres o tutores le leían en voz alta) ----
# Recodificamos la variable con etiquetas claras
p34_3_factor = factor(df_c$p34_3, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_3 = table(p34_3_factor)
# Generamos la tabla de resumen completa
resumen_p34_3 = data.frame(
Categoria = names(frecuencias_p34_3),
Frecuencia = as.vector(frecuencias_p34_3),
Porcentaje = round(prop.table(frecuencias_p34_3) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P34_3 (sus padres o tutores le leían en voz alta)")
print(resumen_p34_2)
# ---- ANÁLISIS DE FRECUENCIA: P34_4 (en su casa había libros distintos a los de texto escolar) ----
# Recodificamos la variable con etiquetas claras
p34_4_factor = factor(df_c$p34_4, levels = c(1, 2, 3), labels = c("Sí", "No", "No recuerda"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p34_4 = table(p34_4_factor)
# Generamos la tabla de resumen completa
resumen_p34_4 = data.frame(
Categoria = names(frecuencias_p34_4),
Frecuencia = as.vector(frecuencias_p34_4),
Porcentaje = round(prop.table(frecuencias_p34_4) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P34_3 (en su casa había libros distintos a los de texto escolar)")
print(resumen_p34_4)
# ---- ANÁLISIS DE FRECUENCIA: P2 (Acostumbra leer) ----
# Recodificamos la variable con etiquetas claras
p2_factor = factor(df_c$p2, levels = c(1, 2), labels = c("Sí", "No"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p2 = table(p2_factor)
# Generamos la tabla de resumen completa
resumen_p2 = data.frame(
Categoria = names(frecuencias_p2),
Frecuencia = as.vector(frecuencias_p2),
Porcentaje = round(prop.table(frecuencias_p2) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P2 (Acostumbra leer)")
print(resumen_p2)
# ---- ANÁLISIS DE FRECUENCIA: P5 (Motivo de lectura de libros) ----
# Recodificamos la variable con etiquetas claras
p5_factor = factor(df_c$p5, levels = c(1, 2, 3, 4, 5, 6), labels = c("Trabajo", "Estudio", "Cultura General", "Gusto/Entretenimiento", "Religión", "Otro"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p5 = table(p5_factor)
# Generamos la tabla de resumen completa
resumen_p5 = data.frame(
Categoria = names(frecuencias_p5),
Frecuencia = as.vector(frecuencias_p5),
Porcentaje = round(prop.table(frecuencias_p5) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P5 (Motivo lectura libros)")
print(resumen_p5)
# ---- ANÁLISIS DE FRECUENCIA: P11 (Motivo de lectura de revistas) ----
# Recodificamos la variable con etiquetas claras
p11_factor = factor(df_c$p11, levels = c(1, 2, 3, 4, 5, 6), labels = c("Trabajo", "Estudio", "Cultura General", "Gusto/Entretenimiento", "Religión", "Otro"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p11 = table(p11_factor)
# Generamos la tabla de resumen completa
resumen_p11 = data.frame(
Categoria = names(frecuencias_p11),
Frecuencia = as.vector(frecuencias_p11),
Porcentaje = round(prop.table(frecuencias_p11) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P11 (Motivo lectura de revistas)")
print(resumen_p11)
# ---- ANÁLISIS DE FRECUENCIA: P17 (Motivo de lectura de periódicos) ----
# Recodificamos la variable con etiquetas claras
p17_factor = factor(df_c$p17, levels = c(1, 2, 3, 4, 5, 6), labels = c("Trabajo", "Estudio", "Cultura General", "Gusto/Entretenimiento", "Religión", "Otro"))
# Calculamos la tabla de frecuencia absoluta
frecuencias_p17 = table(p17_factor)
# Generamos la tabla de resumen completa
resumen_p17 = data.frame(
Categoria = names(frecuencias_p17),
Frecuencia = as.vector(frecuencias_p17),
Porcentaje = round(prop.table(frecuencias_p17) * 100, 2)
)
# Mostramos la tabla
print("Tabla de Frecuencias: P17 (Motivo lectura de periódicos)")
print(resumen_p17)
ggplot(data = df_c[,c("edad","TL")], aes(x=edad,y=TL)) +
geom_jitter(size = 0.7)
ggplot(data = df_c[,c("edad","TL")], aes(x=TL)) +
geom_bar() +
stat_function(fun = dnorm,args = list(mean = mean(df_c$TL), sd = sd(df_c$TL)), linewidth = 1) +
xlim(0,30) +
ylim(0,1500) +
geom_vline(xintercept =mean(df_c$TL), aes(x = TL),color = "red",linewidth=1.3)
data = matrix(c(27,39,44,273,261,356),ncols = 2, byrow = TRUE)
data = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
data = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
data
data = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
colnames(data) = c("Demorado","a tiempo")
data
data = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
colnames(data) = c("Demorado","a tiempo")
rownames(data) = c("Delta","Aerolinea United","US Airways")
data
data1 = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
colnames(data) = c("Demorado","a tiempo")
rownames(data) = c("Delta","Aerolinea United","US Airways")
alpha = 0.05
chisq.test(data1)
data1 = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
colnames(data) = c("Demorado","a tiempo")
rownames(data) = c("Delta","Aerolinea United","US Airways")
alpha = 0.05
chisq.test(data1,correc = FALSE)
data1 = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
colnames(data) = c("Demorado","a tiempo")
rownames(data) = c("Delta","Aerolinea United","US Airways")
alpha = 0.05
data1
chisq.test(data1,correc = FALSE)
data1 = matrix(c(27,39,44,273,261,356),ncol = 2, byrow = TRUE)
colnames(data1) = c("Demorado","a tiempo")
rownames(data1) = c("Delta","Aerolinea United","US Airways")
alpha = 0.05
data1
chisq.test(data1,correc = FALSE)
data1 = matrix(c(27,273,39,261,44,356),ncol = 2, byrow = TRUE)
colnames(data1) = c("Demorado","a tiempo")
rownames(data1) = c("Delta","Aerolinea United","US Airways")
alpha = 0.05
data1
chisq.test(data1,correc = FALSE)
data2= matrix(c(10,15,35,490,485,465),ncol=3,byrow=TRUE)
data2= matrix(c(10,15,35,490,485,465),ncol=3,byrow=TRUE)
colnames(data2) = c("A","B","C")
rownames(data2) = c("Componente","Defectuoso","Bueno")
data2= matrix(c(10,15,35,490,485,465),ncol=3,byrow=TRUE)
colnames(data2) = c("A","B","C")
rownames(data2) = c("Defectuoso","Bueno")
data2
data2= matrix(c(10,15,35,490,485,465),ncol=3,byrow=TRUE)
colnames(data2) = c("A","B","C")
rownames(data2) = c("Defectuoso","Bueno")
data2
alpha = 0.05
chisq.test(data2)
data3 = matrix(c(37,32,19,34,16,42), ncol=2, byrow = TRUE)
data3
data3 = matrix(c(37,32,19,34,16,42), ncol=2, byrow = TRUE)
data3
colnames(data3) = c("Privada","Publica")
rownames(data3) = c("Numero de empleados", "No hay cambios", "Despidos")
data3 = matrix(c(37,32,19,34,16,42), ncol=2, byrow = TRUE)
colnames(data3) = c("Privada","Publica")
rownames(data3) = c("Numero de empleados", "No hay cambios", "Despidos")
data3
data3 = matrix(c(37,32,19,34,16,42), ncol=2, byrow = TRUE)
colnames(data3) = c("Privada","Publica")
rownames(data3) = c("Numero de empleados", "No hay cambios", "Despidos")
data3
chisq.test(data3)
data3 = matrix(c(37,32,19,34,16,42), ncol=2, byrow = TRUE)
colnames(data3) = c("Privada","Publica")
rownames(data3) = c("Numero de empleados", "No hay cambios", "Despidos")
data3
chisq.test(data3)
qchisq(1-alpha,df)
data3 = matrix(c(37,32,19,34,16,42), ncol=2, byrow = TRUE)
colnames(data3) = c("Privada","Publica")
rownames(data3) = c("Numero de empleados", "No hay cambios", "Despidos")
data3
chisq.test(data3)
qchisq(1-alpha,2)
data4 = matrix(c(30,59,82,20,16,18),ncol=3,byrow=TRUE)
data4 = matrix(c(30,59,82,20,16,18),ncol=3,byrow=TRUE)
data4
data4 = matrix(c(30,59,82,20,16,18),ncol=3,byrow=TRUE)
data4
chisq.test(data4)
data3 = matrix(c(37,32,19,34,16,42), ncol=2, byrow = TRUE)
colnames(data3) = c("Privada","Publica")
rownames(data3) = c("Numero de empleados", "No hay cambios", "Despidos")
data3
chisq.test(data3)
alpha=0.01
qchisq(1-alpha,2)
knitr::opts_chunk$set(echo = FALSE)
#setwd("data")
# Install and load required library for combining data frames
if (!require(dplyr, quietly = TRUE)) {
install.packages("dplyr")
library(dplyr)
}
if(!require(ggplot2, quietly = TRUE)) {
install.packages("ggplot2")
library(ggplot2)
}
# Para las medidas de forma
if(!require(moments, quietly = TRUE)) {
install.packages("moments")
library(moments)
}
# Read CSV files individually first
df_2019 <- read.csv("conjunto_de_datos_molec_2019_02.csv")
getwd()
setwd("meptd/data")
getwd()
# Install and load required library for combining data frames
if (!require(dplyr, quietly = TRUE)) {
install.packages("dplyr")
library(dplyr)
}
if(!require(ggplot2, quietly = TRUE)) {
install.packages("ggplot2")
library(ggplot2)
}
# Para las medidas de forma
if(!require(moments, quietly = TRUE)) {
install.packages("moments")
library(moments)
}
# Read CSV files individually first
df_2019 <- read.csv("conjunto_de_datos_molec_2019_02.csv")
getwd(0)
getwd(0)
getwd()
x <- c(2100, 2302, 1951, 2067, 2415, 1883, 2101, 2146, 2278, 2019,
1924, 2183, 2077, 2392, 2286, 2501, 1946, 2161, 2253, 1827)
n <- length(x)
s2 <- var(x)    # varianza muestral
alpha <- 0.10
chi_lower <- qchisq(alpha/2, df = n - 1)
chi_upper <- qchisq(1 - alpha/2, df = n - 1)
IC_lower <- (n - 1) * s2 / chi_upper
IC_upper <- (n - 1) * s2 / chi_lower
IC_lower; IC_upper
c(sqrt(IC_lower), sqrt(IC_upper))
22500 >= IC_lower & 22500 <= IC_upper
s1 <- 5.1
s2 <- 4.7
n1 <- 12
n2 <- 16
s1_2 <- s1^2
s2_2 <- s2^2
alpha <- 0.05
df1 <- n1 - 1
df2 <- n2 - 1
F_lower <- qf(1 - alpha/2, df1, df2)
F_upper <- qf(alpha/2, df1, df2)
ratio <- s1_2 / s2_2
IC_lower <- ratio / F_lower
IC_upper <- ratio / F_upper
IC_lower; IC_upper
if (IC_lower <= 1 && IC_upper >= 1) {
print("✅ 1 está dentro del intervalo → No se detecta diferencia en variabilidad entre procesos.")
} else {
print("⚠️ 1 NO está dentro → Hay evidencia de que las varianzas son diferentes.")
}
s1 <- 5.1
s2 <- 4.7
n1 <- 12
n2 <- 16
s1_2 <- s1^2
s2_2 <- s2^2
alpha <- 0.05
df1 <- n1 - 1
df2 <- n2 - 1
F_lower <- qf(1 - alpha/2, df1, df2)
F_upper <- qf(alpha/2, df1, df2)
ratio <- s1_2 / s2_2
IC_lower <- ratio / F_lower
IC_upper <- ratio / F_upper
IC_lower; IC_upper
if (IC_lower <= 1 && IC_upper >= 1) {
print(" 1 esta dentro del intrevalo  no se detecta diferencia en variabilidad entre procesos")
} else {
print(" 1 NO esta dentrohay evidencia de que las varianzas son diferentes")
}
s1 <- 5.1
s2 <- 4.7
n1 <- 12
n2 <- 16
s1_2 <- s1^2
s2_2 <- s2^2
alpha <- 0.05
df1 <- n1 - 1
df2 <- n2 - 1
F_lower <- qf(1 - alpha/2, df1, df2)
F_upper <- qf(alpha/2, df1, df2)
ratio <- s1_2 / s2_2
IC_lower <- ratio / F_lower
IC_upper <- ratio / F_upper
IC_lower; IC_upper
if (IC_lower <= 1 && IC_upper >= 1) {
print(" 1 esta dentro del intrevalo  no se detecta diferencia en variabilidad entre procesos")
} else {
print(" 1 NO esta dentrohay evidencia de que las varianzas son diferentes")
}
s1 <- 5.1
s2 <- 4.7
n1 <- 12
n2 <- 16
s1_2 <- s1^2
s2_2 <- s2^2
alpha <- 0.05
df1 <- n1 - 1
df2 <- n2 - 1
F_lower <- qf(1 - alpha/2, df1, df2)
F_upper <- qf(alpha/2, df1, df2)
ratio <- s1_2 / s2_2
IC_lower <- ratio / F_lower
IC_upper <- ratio / F_upper
IC_lower; IC_upper
if (IC_lower <= 1 && IC_upper >= 1) {
print(" 1 esta dentro del intrevalo  no se detecta diferencia en variabilidad entre procesos")
} else {
print(" 1 NO esta dentrohay evidencia de que las varianzas son diferentes")
}
A <- c(14.57, 15.01, 13.44, 9.92, 13.123, 13.25, 16.77, 10.948, 13.70, 17.61, 11.90, 16.78)
B <- c(10.39, 10.43, 11.44, 9.71, 11.04, 11.70, 11.14, 9.85, 13.69, 9.47, 11.2, 11.9)
# Varianzas muestrales
s2_A <- var(A)
s2_B <- var(B)
nA <- length(A)
nB <- length(B)
alpha <- 0.05
df1 <- nA - 1
df2 <- nB - 1
F_lower <- qf(1 - alpha/2, df1, df2)
F_upper <- qf(alpha/2, df1, df2)
ratio <- s2_A / s2_B
IC_lower <- ratio / F_lower
IC_upper <- ratio / F_upper
IC_lower; IC_upper
